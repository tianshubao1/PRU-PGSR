{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PGSRipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4sQTz0VbBxd"
      },
      "outputs": [],
      "source": [
        "%tensorflow_version 1.x\n",
        "from __future__ import print_function, division\n",
        "from tensorflow import keras\n",
        "from keras.layers import *\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.applications import VGG19\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "import datetime\n",
        "#from data_loader import DataLoader\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL']='2' \n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "a = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/u_les_all.npy')\n",
        "b = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/v_les_all.npy')\n",
        "c = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/w_les_all.npy')\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "maximum0 = a.max()\n",
        "minimum0 = a.min()\n",
        "print(maximum0,minimum0)\n",
        "maximum1 = b.max()\n",
        "minimum1 = b.min()\n",
        "print(maximum1,minimum1)\n",
        "maximum2 = c.max()\n",
        "minimum2 = c.min()\n",
        "print(maximum2,minimum2)\n",
        "\n",
        "dataset = np.zeros((2600,32,32,3))\n",
        "\n",
        "\n",
        "for i in range(2600):\n",
        "\ttemp = a[i]#u\n",
        "\ttemp1 = b[i]#v\n",
        "\ttemp2 = c[i]#w\n",
        "\t#u\n",
        "\t#temp = (temp - minimum0)/(maximum0 - minimum0)\n",
        "\t#v\n",
        "\t#temp1 = (temp1 - minimum1)/(maximum1 - minimum1)\n",
        "\t#w\n",
        "\t#temp2 = (temp2 - minimum2)/(maximum2 - minimum2)\n",
        "\t\n",
        "\n",
        "\tfor j in range(32):\n",
        "\t\tfor k in range(32):\n",
        "\t\t\tdataset[i][j][k] = np.array([temp[j][k],temp1[j][k],temp2[j][k]])\n",
        "print(dataset.shape)\n",
        "#print(dataset)\n",
        "print(dataset.min())\n",
        "print(dataset.max())\n",
        "\n",
        "######################DNS##################################################\n",
        "\n",
        "\n",
        "\n",
        "######################DNS##################################################\n",
        "# read in dns data from npy file\n",
        "a = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/u_dns_all.npy')\n",
        "b = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/v_dns_all.npy')\n",
        "c = np.load('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time/data90/w_dns_all.npy')\n",
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(c.shape)\n",
        "dataset1 = np.zeros((2600,128,128,3))\n",
        "\n",
        "maximum0_dns = a.max()\n",
        "minimum0_dns = a.min()\n",
        "print(maximum0_dns,minimum0_dns)\n",
        "maximum1_dns = b.max()\n",
        "minimum1_dns = b.min()\n",
        "print(maximum1_dns,minimum1_dns)\n",
        "maximum2_dns = c.max()\n",
        "minimum2_dns = c.min()\n",
        "print(maximum2_dns,minimum2_dns)\n",
        "\n",
        "\n",
        "for i in range(2600):\n",
        "\ttemp = a[i]#u\n",
        "\ttemp1 = b[i]#v\n",
        "\ttemp2 = c[i]#w\n",
        "\t#u\n",
        "\t#temp = (temp - minimum0_dns)/(maximum0_dns - minimum0_dns)\n",
        "\t#v\t\t\n",
        "\t#temp1 = (temp1 - minimum1_dns)/(maximum1_dns - minimum1_dns)\n",
        "\t#w\n",
        "\t#temp2 = (temp2 - minimum2_dns)/(maximum2_dns - minimum2_dns)\n",
        "\n",
        "\t\t\n",
        "\tfor j in range(128):\n",
        "\t\tfor k in range(128):\n",
        "\t\t\tdataset1[i][j][k] = np.array([temp[j][k],temp1[j][k],temp2[j][k]])\n",
        "\n",
        "print(dataset1.shape)\n",
        "print(dataset1.min())\n",
        "print(dataset1.max())\n",
        "\n",
        "\n",
        "\n",
        "def mean(vects):\n",
        "\tu_all = vects[:,:,:,0]\n",
        "\tv_all = vects[:,:,:,1]\n",
        "\tw_all = vects[:,:,:,2]\n",
        "\t\t\t\t\n",
        "\tu = u_all[:65,:,:]\n",
        "\tv = v_all[:65,:,:]\n",
        "\tw = w_all[:65,:,:]\n",
        "\n",
        "\t\n",
        "\tu = u - tf.reduce_mean(u)   \n",
        "\tv = v - tf.reduce_mean(v) \n",
        "\tw = w - tf.reduce_mean(w) \n",
        "\n",
        "\tvects = tf.stack([u,v,w],axis=3)\n",
        "\n",
        "\treturn vects\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####build the model\n",
        "class SRGAN():\n",
        "\tdef __init__(self):\n",
        "\t\t# Input shape\n",
        "\t\tself.channels = 3\n",
        "\t\tself.lr_height = 32  # Low resolution height\n",
        "\t\tself.lr_width = 32  # Low resolution width\n",
        "\t\tself.lr_shape = (self.lr_height, self.lr_width, self.channels)\n",
        "\t\tself.hr_height = 128  # High resolution height\n",
        "\t\tself.hr_width = 128  # High resolution width\n",
        "\t\tself.hr_shape = (self.hr_height, self.hr_width, self.channels)\n",
        "\n",
        "\t\t# Number of residual blocks in the generator\n",
        "\t\tself.n_residual_blocks = 16\n",
        "\n",
        "\t\toptimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "\t\t# We use a pre-trained VGG19 model to extract image features from the high resolution\n",
        "\t\t# and the generated high resolution images and minimize the mse between them\n",
        "\t\tself.vgg = self.build_vgg()\n",
        "\t\tself.vgg.trainable = False\n",
        "\t\tself.vgg.summary()\n",
        "\t\tprint(\"vgg model summary\")\n",
        "\t\tprint(self.vgg.summary())\n",
        "\t\t\n",
        "\t\tself.vgg.compile(loss='mse',\n",
        "\t\t\t\t\t\t optimizer=optimizer,\n",
        "\t\t\t\t\t\t metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "\t\t# Calculate output shape of D (PatchGAN)\n",
        "\t\tpatch = int(self.hr_height / 2 ** 4)\n",
        "\t\tself.disc_patch = (patch, patch, 1)\n",
        "\n",
        "\t\t# Number of filters in the first layer of G and D\n",
        "\t\tself.gf = 64\n",
        "\t\tself.df = 64\n",
        "\n",
        "\t\t# Build and compile the discriminator\n",
        "\t\tself.discriminator = self.build_discriminator()\n",
        "\t\tprint(\"discriminator model\")\n",
        "\t\tprint(self.discriminator.summary())\n",
        "\t\tself.discriminator.compile(loss=[\"mse\",\"mse\"],\n",
        "\t\t\t\t\t\t\t\t   optimizer=optimizer,\n",
        "\t\t\t\t\t\t\t\t   metrics=['mean_squared_error'])\n",
        "\n",
        "\n",
        "\t\t# Build the generator\n",
        "\t\tself.generator= self.build_generator()\n",
        "\t\tprint(\"generator model\")\n",
        "\t\tprint(self.generator.summary())\n",
        "\n",
        "\t\t# High res. and low res. images\n",
        "\t\timg_hr = Input(shape=self.hr_shape)\n",
        "\t\timg_lr = Input(shape=self.lr_shape)\n",
        "\n",
        "\n",
        "\t\t# Generate high res. version from low res.\n",
        "\t\tfake_hr,fake_hrm = self.generator(img_lr)\n",
        "\t\t\n",
        "\n",
        "\t\t# Extract image features of the generated img\n",
        "\t\tfake_features = self.vgg(fake_hr)\n",
        "\t\tfake_features_m = self.vgg(fake_hrm)\n",
        "\n",
        "\t\t# For the combined model we will only train the generator\n",
        "\t\tself.discriminator.trainable = False\n",
        "\n",
        "\t\t# Discriminator determines validity of generated high res. images\n",
        "\t\tvalidity, fake_les = self.discriminator(fake_hr)\n",
        "#\t\t\n",
        "\t\tself.combined = Model([img_lr,img_hr], [validity, fake_features,fake_hr])\n",
        "\n",
        "\t\tself.combined.compile(loss=['binary_crossentropy', \"mse\", self.divergent_loss_tr],\n",
        "\t\t\t\t\t\t\t  loss_weights=[1e-3, 1, 100], \n",
        "\t\t\t\t\t\t\t  optimizer=optimizer,metrics=['mean_squared_error'])\t\n",
        "\t#self.binary_crossentropy\t\t\t\t\t\n",
        "\tdef mean_squared_error(self, y_true, y_pred):\n",
        "\t\tyt = tf.reshape(y_true[:,:,:,:],[-1])\n",
        "\t\typ = tf.reshape(y_pred[:,:,:,:],[-1])\n",
        "\t\treturn  tf.reduce_mean(tf.square(yt-yp))\n",
        "#\t\t\t\n",
        "\t\t\t\t\t\n",
        "\t\t\t\n",
        "\tdef divergent_loss_tr(self, y_true, y_pred):\n",
        "\t\tu = y_pred[:,:,:,0]\n",
        "\t\tv = y_pred[:,:,:,1]\n",
        "\t\tw = y_pred[:,:,:,2]\n",
        "\t\t\n",
        "\n",
        "\t\timg_size = 128\t\n",
        "\t\tnum_img = 65\n",
        "\t\tu1 = tf.concat([tf.zeros([num_img,1,img_size]),u[:,2:,:],tf.zeros([num_img,1,img_size])],axis=1)\n",
        "\t\tu2 = tf.concat([tf.zeros([num_img,1,img_size]),u[:,:-2,:],tf.zeros([num_img,1,img_size])],axis=1)\n",
        "\t\tdu = (u1-u2)\n",
        "\t\t#\tprint(du.shape)\n",
        "\t\t\t\n",
        "\t\tv1 = tf.concat([tf.zeros([num_img,img_size,1]),v[:,:,2:],tf.zeros([num_img,img_size,1])],axis=2)\n",
        "\t\tv2 = tf.concat([tf.zeros([num_img,img_size,1]),v[:,:,:-2],tf.zeros([num_img,img_size,1])],axis=2)\n",
        "\t\tdv = (v1-v2)\n",
        "\t\t#\tprint(dv.shape)\n",
        "\t\t\t\n",
        "\t\tw1 = tf.concat([tf.zeros([1,img_size,img_size]),w[2:,:,:],tf.zeros([1,img_size,img_size])],axis=0)\n",
        "\t\tw2 = tf.concat([tf.zeros([1,img_size,img_size]),w[:-2,:,:],tf.zeros([1,img_size,img_size])],axis=0)\n",
        "\t\tdw = (w1-w2)\n",
        "\n",
        "\t\ts = du+dv+dw/2\n",
        "\t\ts = tf.reshape(s,[-1])\n",
        "\n",
        "\t\tcost_phy = tf.reduce_mean(tf.square(s))\n",
        "\t\t\n",
        "\t\treturn cost_phy\n",
        "\n",
        "\tdef physical_loss_tr(self, y_true, y_pred):\n",
        "\t\tu = y_pred[:,:,:,0]\n",
        "\t\tv = y_pred[:,:,:,1]\n",
        "\t\tw = y_pred[:,:,:,2]\n",
        "\n",
        "\t\tu = tf.reshape(u,[-1])\n",
        "\t\tv = tf.reshape(v,[-1])\n",
        "\t\tw = tf.reshape(w,[-1])\n",
        "\t\t\n",
        "\t\tcost_phy = tf.reduce_mean(tf.square(u)) + tf.reduce_mean(tf.square(v)) + tf.reduce_mean(tf.square(w))\n",
        "\t\t\n",
        "\t\treturn cost_phy\n",
        "\n",
        "\n",
        "\t\t\n",
        "\tdef build_vgg(self):\n",
        "\t\t\"\"\"\n",
        "\t\tBuilds a pre-trained VGG19 model that outputs image features extracted at the\n",
        "\t\tthird block of the model\n",
        "\t\t\"\"\"\n",
        "\t\tprint('start loading trianed weights of vgg...')\n",
        "\t\tvgg = VGG19(weights=\"imagenet\")\n",
        "\t\t# Set outputs to outputs of last conv. layer in block 3\n",
        "\t\t# See architecture at: https://github.com/keras-team/keras/blob/master/keras/applications/vgg19.py\n",
        "\t\tprint('loading completes')\n",
        "\t\tvgg.outputs = [vgg.layers[9].output]\n",
        "\n",
        "\t\timg = Input(shape=self.hr_shape)\n",
        "\n",
        "\t\t# Extract image features\n",
        "\t\timg_features = vgg(img)\n",
        "\n",
        "\t\treturn Model(img, img_features)\n",
        "\n",
        "\tdef build_generator(self):\n",
        "\n",
        "\t\tdef residual_block(layer_input, filters):\n",
        "\t\t\t\"\"\"Residual block described in paper\"\"\"\n",
        "\t\t\td = Conv2D(filters, kernel_size=3, strides=1, padding='same')(layer_input)\n",
        "\t\t\td = Activation('relu')(d)\n",
        "\t\t\td = BatchNormalization(momentum=0.8)(d)\n",
        "\t\t\td = Conv2D(filters, kernel_size=3, strides=1, padding='same')(d)\n",
        "\t\t\td = BatchNormalization(momentum=0.8)(d)\n",
        "\t\t\td = Add()([d, layer_input])\n",
        "\t\t\treturn d\n",
        "\n",
        "\t\tdef deconv2d(layer_input):\n",
        "\t\t\t\"\"\"Layers used during upsampling\"\"\"\n",
        "\t\t\tu = UpSampling2D(size=2)(layer_input)\n",
        "\t\t\tu = Conv2D(256, kernel_size=3, strides=1, padding='same')(u)\n",
        "\t\t\tu = Activation('relu')(u)\n",
        "\t\t\treturn u\n",
        "\n",
        "\t\t# Low resolution image input\n",
        "\t\timg_lr = Input(shape=self.lr_shape)\n",
        "\n",
        "\t\t# Pre-residual block\n",
        "\t\tc1 = Conv2D(64, kernel_size=9, strides=1, padding='same')(img_lr)\n",
        "\t\tc1 = Activation('relu')(c1)\n",
        "\n",
        "\t\t# Propogate through residual blocks\n",
        "\t\tr = residual_block(c1, self.gf)\n",
        "\t\tfor _ in range(self.n_residual_blocks - 1):\n",
        "\t\t\tr = residual_block(r, self.gf)\n",
        "\n",
        "\t\t# Post-residual block\n",
        "\t\tc2 = Conv2D(64, kernel_size=3, strides=1, padding='same')(r)\n",
        "\t\tc2 = BatchNormalization(momentum=0.8)(c2)\n",
        "\t\tc2 = Add()([c2, c1])\n",
        "\t\tgen_hr_m1 = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(c2)\n",
        "\n",
        "\t\t# Upsampling\n",
        "\t\tu1 = deconv2d(c2)\n",
        "\t\tgen_hr_m = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u1)\n",
        "\t\tu2 = deconv2d(u1)\n",
        "\n",
        "\t\t# Generate high resolution output\n",
        "\t\tgen_hr = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(u2)\n",
        "\t\tout = Lambda(mean, output_shape=self.hr_shape)(gen_hr)\n",
        "\n",
        "\t\t#return Model(img_lr, [gen_hr, out])\n",
        "\t\treturn Model(img_lr, [out, gen_hr])\n",
        "\tdef build_discriminator(self):\n",
        "\n",
        "\t\tdef d_block(layer_input, filters, strides=1, bn=True):\n",
        "\t\t\t\"\"\"Discriminator layer\"\"\"\n",
        "\t\t\td = Conv2D(filters, kernel_size=3, strides=strides, padding='same')(layer_input)\n",
        "\t\t\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t\t\tif bn:\n",
        "\t\t\t\td = BatchNormalization(momentum=0.8)(d)\n",
        "\t\t\treturn d\n",
        "\n",
        "\t\t# Input img\n",
        "\t\td0 = Input(shape=self.hr_shape)\n",
        "\n",
        "\t\td1 = d_block(d0, self.df, bn=False)\n",
        "\t\td2 = d_block(d1, self.df, strides=2)\n",
        "\t\td3 = d_block(d2, self.df * 2)\n",
        "\t\td4 = d_block(d3, self.df * 2, strides=2)\n",
        "\t\td5 = d_block(d4, self.df * 4)\n",
        "\t\tout = Conv2D(self.channels, kernel_size=9, strides=1, padding='same', activation='tanh')(d5)\n",
        "\t\t\n",
        "\t\td6 = d_block(d5, self.df * 4, strides=2)\n",
        "\t\td7 = d_block(d6, self.df * 8)\n",
        "\t\td8 = d_block(d7, self.df * 8, strides=2)\n",
        "\n",
        "\t\td9 = Dense(self.df * 16)(d8)\n",
        "\t\td10 = LeakyReLU(alpha=0.2)(d9)\n",
        "\t\tvalidity = Dense(1, activation='sigmoid')(d10)\n",
        "\n",
        "\t\treturn Model(d0, [validity, out])\n",
        "\t\t\n",
        "\n",
        "\tdef train(self, epochs, batch_size, No, LES,DNS):\n",
        "\n",
        "\t\t\n",
        "\t\trmse_output = []\n",
        "\t\tstart_time = datetime.datetime.now()\t\n",
        "\t\tru = 10 \n",
        "\t\trv = 10 \n",
        "\t\trw = 10 \n",
        "\t\tfor epoch in range(1,epochs+1):\n",
        "\n",
        "\t\t\t\n",
        "\t\t\t# ----------------------\n",
        "\t\t\t#  Train Discriminator\n",
        "\t\t\t# ----------------------\n",
        "\n",
        "\t\t\t# Sample images and their conditioning counterparts\n",
        "\t\t\tprint(\"###############################################################r\")\t\t\t\n",
        "\t\t\tprint(\"training discriminator\")\n",
        "\t\t\tfor i in range(20):\n",
        "\t\t\t\t\n",
        "\t\t\t\tprint(\"epoch: \" + str(epoch)+\", batch: \"+str(i))\n",
        "\t\t\t\tprint(\"training no: \", 0+65*i,65+65*i)\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\timgs_hr = DNS[0+65*i:65+65*i,:,:,:]\n",
        "\t\t\t\timgs_lr = LES[0+65*i:65+65*i,:,:,:]\n",
        "#\t\t\t\timgs_hr, imgs_lr = DNS[0+65*i:65+65*i,:,:,:], LES[0+65*i:65+65*i,:,:,:]\n",
        "\t\t\n",
        "\t\t\t\t# From low res. image generate high res. version\n",
        "\t\t\t\tfake_hr,fake_hrm = self.generator.predict(imgs_lr)\n",
        "\n",
        "\t\t\t\t\n",
        "\t\t\t\t#calculate mean square error:\n",
        "\t\t\t\t\n",
        "\t\t\t\tvalid = np.ones((batch_size,) + self.disc_patch)\n",
        "\t\t\t\tfake = np.zeros((batch_size,) + self.disc_patch)\n",
        "\t\t\t\t\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t# Train the discriminators (original images = real / generated = Fake)\n",
        "\t\t\t\td_loss_real = self.discriminator.train_on_batch(imgs_hr, [valid,imgs_lr])\n",
        "\t\t\t\td_loss_fake = self.discriminator.train_on_batch(fake_hr, [fake,imgs_lr])\n",
        "\t\t\t\td_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\t\t\t\tprint(epoch,'d',\"batch: \"+str(i),d_loss)\n",
        "\n",
        "\t\t\t# ------------------\n",
        "\t\t\t#  Train Generator\n",
        "\t\t\t# ------------------\n",
        "\t\t\tprint(\"training generator\")\n",
        "\t\t\tfor i in range(20):\n",
        "\t\t\t\tprint(\"epoch: \" + str(epoch)+\", batch: \"+str(i))\n",
        "\t\t\t\tprint(\"training no: \", 0+65*i,65+65*i)\n",
        "\n",
        "\n",
        "\t\t\t\t# Sample images and their conditioning counterparts\n",
        "\t\t\t\timgs_hr = DNS[0+65*i:65+65*i,:,:,:]\n",
        "\t\t\t\timgs_lr = LES[0+65*i:65+65*i,:,:,:]\n",
        "\t\t\t\t\n",
        "\n",
        "\n",
        "\t\t\t\t# The generators want the discriminators to label the generated images as real\n",
        "\t\t\t\tvalid = np.ones((batch_size,) + self.disc_patch)\n",
        "\n",
        "\t\t\t\t# Extract ground truth image features using pre-trained VGG19 model\n",
        "\t\t\t\timage_features = self.vgg.predict(imgs_hr)\n",
        "\n",
        "\n",
        "\t\t\t\t# Train the generators\n",
        "\t\t\t\tg_loss = self.combined.train_on_batch([imgs_lr,imgs_hr], [valid, image_features, imgs_hr])\n",
        "\t\t\t\tprint(epoch, \"g\",\"batch \"+str(i),g_loss)\n",
        "#\t\t\t\tprint(type(g_loss))\n",
        "\n",
        "\t\t\telapsed_time = datetime.datetime.now() - start_time\n",
        "\t\t\t# Plot the progress\n",
        "\t\t\tprint(\"%d time: %s\" % (epoch, elapsed_time))\n",
        "\t\t\t\n",
        "\t\t\t# If at save interval => save generated image samples\n",
        "\t\t\tif epoch % 10 == 0 and epoch > 100 and No == 1:\n",
        "\t\t\t\tself.discriminator.save_weights('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time1130/model_D/' + str(epoch) + 'save_0_500.h5')\n",
        "\t\t\t\tself.generator.save_weights('/content/drive/My Drive/PGSRN(Model and Data)/PGSRN_across_time1130/model_G/' + str(epoch) + 'save_0_500.h5')\n",
        "\t\t\t\n",
        "\t\t\tprint(\"calculate all testing RMSE: \")\n",
        "\t\t\timgs_hr, imgs_lr = DNS,LES\n",
        "\t\t\timgs_hr_test, imgs_lr_test = DNS[1300:1625,:,:,:],LES[1300:1625,:,:,:]\n",
        "\t\t\t\n",
        "\t\t\t\n",
        "\t\t\tp1,fake_hrm1_ = gan.generator.predict(imgs_lr_test[:65,:,:,:])\n",
        "\t\t\tp2,fake_hrm2 = gan.generator.predict(imgs_lr_test[65:130,:,:,:])\n",
        "\t\t\tp3,fake_hrm3 = gan.generator.predict(imgs_lr_test[130:195,:,:,:])\n",
        "\t\t\tp4,fake_hrm4 = gan.generator.predict(imgs_lr_test[195:260,:,:,:])\n",
        "\t\t\tp5,fake_hrm5 = gan.generator.predict(imgs_lr_test[260:,:,:,:])\n",
        "\t\t\tprint(p1.shape, p2.shape, p3.shape, p4.shape, p5.shape)\n",
        "\t\t\t\n",
        "\t\t\tpred = np.concatenate((p1,p2,p3,p4,p5))\n",
        "\t\t\tprint(pred.shape)\n",
        "\t\t\ta = pred[:,:,:,0]#*(maximum0_dns - minimum0_dns)+ minimum0_dns#u\n",
        "\t\t\tb = pred[:,:,:,1]#*(maximum1_dns - minimum1_dns)+ minimum1_dns#v\n",
        "\t\t\tc = pred[:,:,:,2]#*(maximum2_dns - minimum2_dns)+ minimum2_dns#w\n",
        "\t\t\t\n",
        "            \n",
        "\t\t\ta1 = imgs_hr_test[:,:,:,0]#*(maximum0_dns - minimum0_dns)+ minimum0_dns#u\n",
        "\t\t\tb1 = imgs_hr_test[:,:,:,1]#*(maximum1_dns - minimum1_dns)+ minimum1_dns#v\n",
        "\t\t\tc1 = imgs_hr_test[:,:,:,2]#*(maximum2_dns - minimum2_dns)+ minimum2_dns#w\n",
        "\t\t\t\n",
        "\t\t\trmse_ua = np.sqrt(np.sum(np.square(a[:,:,:]-a1[:,:,:]))/(325*128*128))\n",
        "\t\t\trmse_va = np.sqrt(np.sum(np.square(b[:,:,:]-b1[:,:,:]))/(325*128*128))\n",
        "\t\t\trmse_wa = np.sqrt(np.sum(np.square(c[:,:,:]-c1[:,:,:]))/(325*128*128))\n",
        "\n",
        "\t\t\tprint(\"RMSE testing all:\",rmse_ua,rmse_va,rmse_wa)\n",
        "\n",
        "\n",
        "######for training\n",
        "gan = SRGAN()\n",
        "gan.train(500, 65,1, dataset,dataset1)\n",
        "\n"
      ]
    }
  ]
}